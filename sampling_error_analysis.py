import os
import json
import re
import sys
from pathlib import Path
from collections import defaultdict
from pydantic import BaseModel
from typing import Literal
from joblib import Parallel, delayed
from tqdm import tqdm
import math

ROOT_DIR = Path(__file__).resolve().parent
SRC_DIR = ROOT_DIR / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))


class ThoughtAnalysis(BaseModel):
    """LLM ë¶„ì„ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ"""
    expected_next_action: Literal["U", "D", "L", "R", "Unknown"]


def extract_thought_and_action(content: str) -> tuple[str | None, str | None, str | None]:
    """
    contentì—ì„œ Thoughtì™€ Actionì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    Returns: (thought_text, inferred_action, actual_action)
    """
    # Action ë¼ì¸ì—ì„œ ì‹¤ì œ action ì¶”ì¶œ (ì˜ˆ: "Action: R" -> "R")
    action_match = re.search(r'Action:\s*([A-Za-z]+)', content)
    actual_action = action_match.group(1).strip() if action_match else None
    
    # Thought ë¶€ë¶„ ì¶”ì¶œ
    thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|$)', content, re.DOTALL)
    thought_text = thought_match.group(1).strip() if thought_match else None
    
    # Rule-basedë¡œ Thoughtì—ì„œ ì¶” inferenceë˜ëŠ” action ì¶”ì¶œ
    inferred_action = None
    if thought_text:
        inferred_action = infer_action_from_thought_rule_based(thought_text)
    
    return thought_text, inferred_action, actual_action


def extract_observation_from_user_message(content: str) -> tuple[str | None, int | None]:
    """
    user messageì—ì„œ observationê³¼ steps_remainingì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    observation = None
    steps_remaining = None
    
    # Observation ì¶”ì¶œ
    obs_match = re.search(r'Observation:\s*(.*?)(?=Steps remaining:|$)', content, re.DOTALL)
    if obs_match:
        observation = obs_match.group(1).strip()
    
    # Steps remaining ì¶”ì¶œ
    steps_match = re.search(r'Steps remaining:\s*(\d+)', content)
    if steps_match:
        steps_remaining = int(steps_match.group(1))
    
    return observation, steps_remaining


def infer_action_from_thought_rule_based(thought: str) -> str | None:
    """
    Rule-based: Thought í…ìŠ¤íŠ¸ì—ì„œ ì˜ë„ëœ actionì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
    """
    thought_lower = thought.lower()
    
    # ë°©í–¥ ë§¤í•‘ (ë‹¤ì–‘í•œ í‘œí˜„ ê³ ë ¤)
    direction_patterns = {
        'U': [
            r'\bup\b', r'\bmove up\b', r'\bgo up\b', r'\bpush up\b',
            r'\bupward\b', r'\bnorth\b', r'\bìœ„\b', r'\bìœ„ë¡œ\b'
        ],
        'D': [
            r'\bdown\b', r'\bmove down\b', r'\bgo down\b', r'\bpush down\b',
            r'\bdownward\b', r'\bsouth\b', r'\bì•„ë˜\b', r'\bì•„ë˜ë¡œ\b'
        ],
        'L': [
            r'\bleft\b', r'\bmove left\b', r'\bgo left\b', r'\bpush left\b',
            r'\bleftward\b', r'\bwest\b', r'\bì™¼ìª½\b', r'\bì™¼ìª½ìœ¼ë¡œ\b'
        ],
        'R': [
            r'\bright\b', r'\bmove right\b', r'\bgo right\b', r'\bpush right\b',
            r'\brightward\b', r'\beast\b', r'\bì˜¤ë¥¸ìª½\b', r'\bì˜¤ë¥¸ìª½ìœ¼ë¡œ\b'
        ]
    }
    
    # ë§ˆì§€ë§‰ ë¬¸ì¥ì—ì„œ ë¨¼ì € ì°¾ê¸° (ì˜ë„ê°€ ë§ˆì§€ë§‰ì— ëª…ì‹œë˜ëŠ” ê²½ìš°ê°€ ë§ìŒ)
    sentences = thought.split('.')
    last_sentences = sentences[-3:] if len(sentences) >= 3 else sentences
    last_part = '.'.join(last_sentences).lower()
    
    # ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ ë¨¼ì € ê²€ìƒ‰
    for action, patterns in direction_patterns.items():
        for pattern in patterns:
            if re.search(pattern, last_part):
                return action
    
    # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰ (ë§ˆì§€ë§‰ ë“±ì¥ ê¸°ì¤€)
    last_found = None
    last_pos = -1
    
    for action, patterns in direction_patterns.items():
        for pattern in patterns:
            matches = list(re.finditer(pattern, thought_lower))
            if matches:
                pos = matches[-1].end()
                if pos > last_pos:
                    last_pos = pos
                    last_found = action
    
    return last_found


def analyze_single_thought_with_llm(
    thought: str,
    model: str = "gpt-4.1-mini"
) -> str | None:
    """
    ë‹¨ì¼ Thoughtë¥¼ LLMìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    """
    from real_agents.base import BaseAgent
    
    try:
        agent = BaseAgent(
            model=model,
            fine_tuned_model=None,
            temperature=0.0,
            is_print=False,
        )
        
        system_prompt = """You are an expert at analyzing reasoning text from a Sokoban puzzle game.
Your task is to determine what the IMMEDIATE NEXT action the player intends to take based on their thought process.

The available actions are:
- U: Move up (x, y) -> (x, y+1)
- D: Move down (x, y) -> (x, y-1)
- L: Move left (x, y) -> (x-1, y)
- R: Move right (x, y) -> (x+1, y)
- Unknown: Cannot determine the intended action from the thought

Analyze the thought carefully and identify what action they plan to execute NEXT (not later steps in a plan).
Focus on phrases like "I will move...", "I should go...", "Next I need to...", "My immediate action is..." etc.
If the thought does not clearly indicate a specific direction, return "Unknown"."""

        user_prompt = f"""Analyze this thought and determine the immediate next action:

Thought: {thought}

What is the immediate next action (U/D/L/R/Unknown) the player intends to take?"""

        response = agent.call_llm(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "thought_analysis",
                    "strict": True,
                    "schema": {
                        "type": "object",
                        "properties": {
                            "expected_next_action": {
                                "type": "string",
                                "enum": ["U", "D", "L", "R", "Unknown"],
                                "description": "The immediate next action inferred from the thought, or Unknown if unclear"
                            }
                        },
                        "required": ["expected_next_action"],
                        "additionalProperties": False
                    }
                }
            }
        )
        
        result = json.loads(response[0])
        action = result.get("expected_next_action")
        # "Unknown"ì¸ ê²½ìš° Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ unknown ì¹´ìš´íŠ¸ì— í¬í•¨
        return None if action == "Unknown" else action
        
    except Exception as e:
        print(f"LLM analysis error: {e}")
        return None


class ThoughtAnalyzer:
    """LLMì„ ì‚¬ìš©í•œ Thought ë¶„ì„ê¸°"""
    
    def __init__(self, model: str = "gpt-4.1-mini"):
        from real_agents.base import BaseAgent
        self.model = model
        self.agent = BaseAgent(
            model=model,
            fine_tuned_model=None,
            temperature=0.0,
            is_print=False,
        )
        
    def analyze(self, thought: str) -> str | None:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ Thoughtì—ì„œ ì˜ë„ëœ ë‹¤ìŒ actionì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
        """
        system_prompt = """You are an expert at analyzing reasoning text from a Sokoban puzzle game.
Your task is to determine what the IMMEDIATE NEXT action the player intends to take based on their thought process.

The available actions are:
- U: Move up
- D: Move down  
- L: Move left
- R: Move right
- Unknown: Cannot determine the intended action from the thought

Analyze the thought carefully and identify what action they plan to execute NEXT (not later steps in a plan).
Focus on phrases like "I will move...", "I should go...", "Next I need to...", "My immediate action is..." etc.
If the thought does not clearly indicate a specific direction, return "Unknown"."""

        user_prompt = f"""Analyze this thought and determine the **immediate** next action:

Thought: {thought}

What is the immediate next action (U/D/L/R/Unknown) the player intends to take?"""

        try:
            response = self.agent.call_llm(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "thought_analysis",
                        "strict": True,
                        "schema": {
                            "type": "object",
                            "properties": {
                                "expected_next_action": {
                                    "type": "string",
                                    "enum": ["U", "D", "L", "R", "Unknown"],
                                    "description": "The immediate next action inferred from the thought, or Unknown if unclear"
                                },
                                "reasoning": {
                                    "type": "string",
                                    "description": "Brief explanation of why this action was inferred"
                                }
                            },
                            "required": ["expected_next_action", "reasoning"],
                            "additionalProperties": False
                        }
                    }
                }
            )
            
            result = json.loads(response[0])
            action = result.get("expected_next_action")
            # "Unknown"ì¸ ê²½ìš° Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ unknown ì¹´ìš´íŠ¸ì— í¬í•¨
            return None if action == "Unknown" else action
            
        except Exception as e:
            print(f"LLM analysis error: {e}")
            return None


def extract_all_thoughts_from_file(filepath: str) -> list[dict]:
    """
    íŒŒì¼ì—ì„œ ëª¨ë“  Thought-Action ìŒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    thoughts = []
    
    if 'messages' in data:
        messages = data['messages']
    elif isinstance(data, list):
        messages = data
    else:
        return thoughts
    
    for i, msg in enumerate(messages):
        if isinstance(msg, dict) and msg.get('role') == 'assistant':
            content = msg.get('content', '')
            if not content or 'Thought:' not in content:
                continue
            
            thought_text, rule_inferred, actual = extract_thought_and_action(content)
            
            # ì§ì „ user messageì—ì„œ observationê³¼ steps_remaining ì¶”ì¶œ
            observation = None
            steps_remaining = None
            if i > 0 and messages[i-1].get('role') == 'user':
                user_content = messages[i-1].get('content', '')
                observation, steps_remaining = extract_observation_from_user_message(user_content)
            
            thoughts.append({
                'step': i,
                'thought': thought_text,
                'rule_inferred': rule_inferred,
                'actual': actual,
                'content': content,
                'observation': observation,
                'steps_remaining': steps_remaining,
            })
    
    return thoughts


def analyze_file(
    filepath: str, 
    use_llm: bool = False, 
    llm_analyzer: ThoughtAnalyzer | None = None
) -> dict:
    """
    ë‹¨ì¼ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ Thought-Action ë¶ˆì¼ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = {
        'total_steps': 0,
        'matched': 0,
        'mismatched': 0,
        'unknown': 0,
        'mismatches': [],
        'unknown_cases': [],
        'step_logs': [],  # ëª¨ë“  stepì˜ ìƒì„¸ ë¡œê·¸
        'analysis_method': 'llm' if use_llm else 'rule-based'
    }
    
    # messagesì—ì„œ assistant ì‘ë‹µ ë¶„ì„
    if 'messages' in data:
        messages = data['messages']
    elif isinstance(data, list):
        messages = data
    else:
        return results
    
    for i, msg in enumerate(messages):
        if isinstance(msg, dict) and msg.get('role') == 'assistant':
            content = msg.get('content', '')
            if not content or 'Thought:' not in content:
                continue
            
            results['total_steps'] += 1
            thought_text, rule_inferred, actual = extract_thought_and_action(content)
            
            # ì§ì „ user messageì—ì„œ observationê³¼ steps_remaining ì¶”ì¶œ
            observation = None
            steps_remaining = None
            if i > 0 and messages[i-1].get('role') == 'user':
                user_content = messages[i-1].get('content', '')
                observation, steps_remaining = extract_observation_from_user_message(user_content)
            
            # LLM ë˜ëŠ” Rule-based ì„ íƒ
            if use_llm and llm_analyzer and thought_text:
                inferred = llm_analyzer.analyze(thought_text)
            else:
                inferred = rule_inferred
            
            # actual_actionì´ Noneì´ê³  inferredë„ None(Unknown)ì¸ ê²½ìš° matchë¡œ ì²˜ë¦¬
            if actual is None and inferred is None:
                is_match = True
            elif inferred is None:
                is_match = False
            else:
                is_match = (inferred == actual)
            
            # step log ì €ì¥
            step_log = {
                'step': i,
                'observation': observation,
                'steps_remaining': steps_remaining,
                'thought': thought_text[:500] if thought_text else None,
                'inferred_action': inferred if inferred else 'Unknown',
                'actual_action': actual,
                'is_match': is_match,
            }
            results['step_logs'].append(step_log)
            
            if is_match:
                results['matched'] += 1
                if inferred is None:
                    results['unknown'] += 1  # Unknownì´ì§€ë§Œ actualë„ Noneì´ë¼ match
            elif inferred is None:
                # Unknownì´ê³  actualì€ ìˆëŠ” ê²½ìš° -> mismatch
                results['unknown'] += 1
                results['mismatched'] += 1
                results['unknown_cases'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
                results['mismatches'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'inferred_action': 'Unknown',
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
            else:
                results['mismatched'] += 1
                results['mismatches'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'inferred_action': inferred,
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
    
    return results


def analyze_file_ours(filepath: str) -> dict:
    """
    'ours' í´ë”ìš© íŒŒì¼ ë¶„ì„ í•¨ìˆ˜.
    inferred_action = actual_actionìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ í•­ìƒ matchë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = {
        'total_steps': 0,
        'matched': 0,
        'mismatched': 0,
        'unknown': 0,
        'mismatches': [],
        'unknown_cases': [],
        'step_logs': [],
        'analysis_method': 'ours (inferred=actual)'
    }
    
    if 'messages' in data:
        messages = data['messages']
    elif isinstance(data, list):
        messages = data
    else:
        return results
    
    for i, msg in enumerate(messages):
        if isinstance(msg, dict) and msg.get('role') == 'assistant':
            content = msg.get('content', '')
            if not content or 'Thought:' not in content:
                continue
            
            results['total_steps'] += 1
            thought_text, _, actual = extract_thought_and_action(content)
            
            # ì§ì „ user messageì—ì„œ observationê³¼ steps_remaining ì¶”ì¶œ
            observation = None
            steps_remaining = None
            if i > 0 and messages[i-1].get('role') == 'user':
                user_content = messages[i-1].get('content', '')
                observation, steps_remaining = extract_observation_from_user_message(user_content)
            
            # oursì˜ ê²½ìš°: inferred = actual (í•­ìƒ match)
            inferred = actual
            is_match = True
            
            step_log = {
                'step': i,
                'observation': observation,
                'steps_remaining': steps_remaining,
                'thought': thought_text[:500] if thought_text else None,
                'inferred_action': inferred if inferred else 'Unknown',
                'actual_action': actual,
                'is_match': is_match,
            }
            results['step_logs'].append(step_log)
            results['matched'] += 1
    
    return results


def analyze_file_parallel(
    filepath: str,
    llm_results: dict[str, str] | None = None
) -> tuple[str, dict]:
    """
    ë³‘ë ¬ ì²˜ë¦¬ìš© íŒŒì¼ ë¶„ì„ í•¨ìˆ˜.
    llm_resultsê°€ ì œê³µë˜ë©´ LLM ê²°ê³¼ë¥¼ ì‚¬ìš©, ì•„ë‹ˆë©´ rule-based.
    """
    filename = Path(filepath).name
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = {
        'total_steps': 0,
        'matched': 0,
        'mismatched': 0,
        'unknown': 0,
        'mismatches': [],
        'unknown_cases': [],
        'step_logs': [],  # ëª¨ë“  stepì˜ ìƒì„¸ ë¡œê·¸
        'analysis_method': 'llm' if llm_results else 'rule-based'
    }
    
    if 'messages' in data:
        messages = data['messages']
    elif isinstance(data, list):
        messages = data
    else:
        return filename, results
    
    for i, msg in enumerate(messages):
        if isinstance(msg, dict) and msg.get('role') == 'assistant':
            content = msg.get('content', '')
            if not content or 'Thought:' not in content:
                continue
            
            results['total_steps'] += 1
            thought_text, rule_inferred, actual = extract_thought_and_action(content)
            
            # ì§ì „ user messageì—ì„œ observationê³¼ steps_remaining ì¶”ì¶œ
            observation = None
            steps_remaining = None
            if i > 0 and messages[i-1].get('role') == 'user':
                user_content = messages[i-1].get('content', '')
                observation, steps_remaining = extract_observation_from_user_message(user_content)
            
            # LLM ê²°ê³¼ ì‚¬ìš© ë˜ëŠ” rule-based
            key = f"{filename}_{i}"
            if llm_results and key in llm_results:
                inferred = llm_results[key]
            else:
                inferred = rule_inferred
            
            # actual_actionì´ Noneì´ê³  inferredë„ None(Unknown)ì¸ ê²½ìš° matchë¡œ ì²˜ë¦¬
            if actual is None and inferred is None:
                is_match = True
            elif inferred is None:
                is_match = False
            else:
                is_match = (inferred == actual)
            
            # step log ì €ì¥
            step_log = {
                'step': i,
                'observation': observation,
                'steps_remaining': steps_remaining,
                'thought': thought_text[:500] if thought_text else None,
                'inferred_action': inferred if inferred else 'Unknown',
                'actual_action': actual,
                'is_match': is_match,
            }
            results['step_logs'].append(step_log)
            
            if is_match:
                results['matched'] += 1
                if inferred is None:
                    results['unknown'] += 1  # Unknownì´ì§€ë§Œ actualë„ Noneì´ë¼ match
            elif inferred is None:
                # Unknownì´ê³  actualì€ ìˆëŠ” ê²½ìš° -> mismatch
                results['unknown'] += 1
                results['mismatched'] += 1
                results['unknown_cases'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
                results['mismatches'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'inferred_action': 'Unknown',
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
            else:
                results['mismatched'] += 1
                results['mismatches'].append({
                    'step': i,
                    'observation': observation,
                    'steps_remaining': steps_remaining,
                    'inferred_action': inferred,
                    'actual_action': actual,
                    'thought': thought_text[:500] if thought_text else None,
                    'content_preview': content[:500] + '...' if len(content) > 500 else content
                })
    
    return filename, results


def calculate_stats(values: list[int]) -> tuple[float, float, int]:
    """
    ì´ì§„ ë°ì´í„°(0/1)ì— ëŒ€í•œ í‰ê· ê³¼ Standard Errorë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    Returns: (mean, standard_error, n)
    """
    n = len(values)
    if n == 0:
        return 0.0, 0.0, 0
    
    mean = sum(values) / n
    
    # Standard Error for Binary Data (Bernoulli trial)
    # SE = sqrt( p * (1-p) / n )
    if n > 1:
        se = math.sqrt(mean * (1.0 - mean) / n)
    else:
        se = 0.0
    
    return mean, se, n


def print_summary(results: dict):
    """
    ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    total = max(results['total_steps'], 1)
    matched = results['total_matched']
    mismatched = results['total_mismatched']
    unknown = results['total_unknown']
    
    # ê° ë¹„ìœ¨ ê³„ì‚°
    match_rate = matched / total
    mismatch_rate = mismatched / total
    unknown_rate = unknown / total
    
    # Standard Error ê³„ì‚° (ì´ì§„ ë°ì´í„°)
    match_se = math.sqrt(match_rate * (1 - match_rate) / total) if total > 1 else 0.0
    mismatch_se = math.sqrt(mismatch_rate * (1 - mismatch_rate) / total) if total > 1 else 0.0
    unknown_se = math.sqrt(unknown_rate * (1 - unknown_rate) / total) if total > 1 else 0.0
    
    print("\n" + "=" * 60)
    print(f"ğŸ“ í´ë”: {results['folder']}")
    print(f"ğŸ”§ ë¶„ì„ ë°©ë²•: {results['analysis_method']}", end="")
    if results.get('llm_model'):
        print(f" ({results['llm_model']})")
    else:
        print()
    print("=" * 60)
    
    print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
    print(f"   - ë¶„ì„í•œ íŒŒì¼ ìˆ˜: {results['total_files']}")
    print(f"   - ì „ì²´ ìŠ¤í… ìˆ˜: {results['total_steps']}")
    print(f"   - âœ… ì¼ì¹˜: {matched} ({match_rate*100:.1f}% Â± {match_se*100:.1f}%)")
    print(f"   - âŒ ë¶ˆì¼ì¹˜ (Unknown í¬í•¨): {mismatched} ({mismatch_rate*100:.1f}% Â± {mismatch_se*100:.1f}%)")
    print(f"   - â“ ê·¸ ì¤‘ Unknown: {unknown} ({unknown_rate*100:.1f}% Â± {unknown_se*100:.1f}%)")
    
    if results['all_mismatches']:
        print(f"\nğŸ” ë¶ˆì¼ì¹˜ ìƒì„¸ (ìµœëŒ€ 10ê°œ):")
        print("-" * 60)
        for i, mismatch in enumerate(results['all_mismatches'][:10]):
            print(f"\n[{i+1}] íŒŒì¼: {mismatch['file']}, Step: {mismatch['step']}")
            print(f"    ì¶”ë¡ ëœ Action: {mismatch['inferred_action']} â†’ ì‹¤ì œ Action: {mismatch['actual_action']}")
            if mismatch.get('thought'):
                thought_preview = mismatch['thought'][:200].replace('\n', ' ')
                print(f"    Thought: {thought_preview}...")
        
        if len(results['all_mismatches']) > 10:
            print(f"\n    ... ì™¸ {len(results['all_mismatches']) - 10}ê°œ ë” ìˆìŒ")


def print_file_breakdown(results: dict):
    """
    íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 60)
    print("ğŸ“„ íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼:")
    print("=" * 60)
    
    for filename, file_results in sorted(results['files'].items()):
        total = file_results['total_steps']
        if total == 0:
            continue
            
        matched = file_results['matched']
        mismatched = file_results['mismatched']
        unknown = file_results['unknown']
        
        status = "âœ…" if mismatched == 0 else "âš ï¸" if mismatched < total * 0.3 else "âŒ"
        print(f"\n{status} {filename}")
        print(f"   Steps: {total} | ì¼ì¹˜: {matched} | ë¶ˆì¼ì¹˜: {mismatched} | ì¶”ë¡ ë¶ˆê°€: {unknown}")
        
        if file_results['mismatches']:
            for m in file_results['mismatches'][:3]:
                print(f"      - Step {m['step']}: {m['inferred_action']} â†’ {m['actual_action']}")


def recalculate_stats_from_file(filepath: str) -> dict:
    """
    ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ì„ ì½ì–´ì„œ statsë§Œ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.
    Unknownë„ mismatchì— í¬í•¨í•˜ì—¬ ì¬ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # unknownì„ mismatchì— í¬í•¨í•˜ì—¬ ì¬ê³„ì‚°
    total = max(data['total_steps'], 1)
    matched = data['total_matched']
    unknown = data['total_unknown']
    
    # mismatch = ê¸°ì¡´ mismatch + unknown (ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°)
    # ìƒˆ ë¡œì§: mismatchedëŠ” ì´ë¯¸ unknownì„ í¬í•¨
    mismatched = data['total_mismatched']
    
    # ë¹„ìœ¨ ê³„ì‚°
    match_rate = matched / total
    mismatch_rate = mismatched / total
    unknown_rate = unknown / total
    
    # Standard Error ê³„ì‚°
    match_se = math.sqrt(match_rate * (1 - match_rate) / total) if total > 1 else 0.0
    mismatch_se = math.sqrt(mismatch_rate * (1 - mismatch_rate) / total) if total > 1 else 0.0
    unknown_se = math.sqrt(unknown_rate * (1 - unknown_rate) / total) if total > 1 else 0.0
    
    # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
    data['match_rate'] = match_rate
    data['match_se'] = match_se
    data['match_rate_formatted'] = f"{match_rate:.3f} Â± {match_se:.3f}"
    data['mismatch_rate'] = mismatch_rate
    data['mismatch_se'] = mismatch_se
    data['mismatch_rate_formatted'] = f"{mismatch_rate:.3f} Â± {mismatch_se:.3f}"
    data['unknown_rate'] = unknown_rate
    data['unknown_se'] = unknown_se
    data['unknown_rate_formatted'] = f"{unknown_rate:.3f} Â± {unknown_se:.3f}"
    
    # files_summaryë„ ì—…ë°ì´íŠ¸
    if 'files_summary' in data:
        for name, r in data['files_summary'].items():
            file_total = max(r.get('total', 1), 1)
            file_unknown = r.get('unknown', 0)
            file_mismatched = r.get('mismatched', 0)
            # unknownì„ mismatchì— í¬í•¨ (ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ)
            r['match_rate'] = r.get('matched', 0) / file_total
            r['mismatch_rate'] = file_mismatched / file_total
    
    return data


def analyze_folder(
    folder_path: str, 
    use_llm: bool = False,
    llm_model: str = "gpt-4.1-mini",
    n_jobs: int = -1,
    verbose: bool = True
) -> dict:
    """
    í´ë” ë‚´ì˜ ëª¨ë“  JSON íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    use_llm=Trueì´ê³  n_jobs != 1ì´ë©´ joblibìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    folder = Path(folder_path)
    if not folder.exists():
        print(f"Error: í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return {}

    # "ours"ê°€ ê²½ë¡œì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ inferred_action = actual_actionìœ¼ë¡œ ì²˜ë¦¬
    is_ours = "ours" in folder_path.lower()
    
    if is_ours:
        analysis_method = 'ours (inferred=actual)'
    elif use_llm:
        analysis_method = 'llm'
    else:
        analysis_method = 'rule-based'
    
    all_results = {
        'folder': folder_path,
        'analysis_method': analysis_method,
        'llm_model': llm_model if use_llm and not is_ours else None,
        'total_files': 0,
        'total_steps': 0,
        'total_matched': 0,
        'total_mismatched': 0,
        'total_unknown': 0,
        'files': {},
        'all_mismatches': []
    }
    
    json_files = sorted(list(folder.glob('*.json')))
    
    if not json_files:
        print(f"Warning: JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        return all_results
    
    if is_ours:
        # "ours" í´ë”ì˜ ê²½ìš°: inferred_action = actual_actionìœ¼ë¡œ ì²˜ë¦¬ (í•­ìƒ match)
        if verbose:
            print(f"ğŸ“‹ 'ours' í´ë” ê°ì§€: inferred_action = actual_actionìœ¼ë¡œ ì²˜ë¦¬")
        
        for idx, json_file in enumerate(json_files):
            if verbose:
                print(f"\rğŸ“„ ë¶„ì„ ì¤‘: {idx + 1}/{len(json_files)} - {json_file.name}", end="")
            
            try:
                file_results = analyze_file_ours(str(json_file))
                all_results['total_files'] += 1
                all_results['total_steps'] += file_results['total_steps']
                all_results['total_matched'] += file_results['matched']
                all_results['total_mismatched'] += file_results['mismatched']
                all_results['total_unknown'] += file_results['unknown']
                all_results['files'][json_file.name] = file_results
                
                for mismatch in file_results['mismatches']:
                    mismatch['file'] = json_file.name
                    all_results['all_mismatches'].append(mismatch)
                    
            except Exception as e:
                if verbose:
                    print(f"\nError processing {json_file}: {e}")
        
        if verbose:
            print()
    
    elif use_llm:
        # LLM ë³‘ë ¬ ì²˜ë¦¬
        print(f"ğŸ¤– LLM ë¶„ì„ ì‹œì‘ (model: {llm_model}, jobs: {n_jobs})")
        
        # Step 1: ëª¨ë“  íŒŒì¼ì—ì„œ thoughts ì¶”ì¶œ
        all_thoughts = []
        for json_file in json_files:
            thoughts = extract_all_thoughts_from_file(str(json_file))
            for t in thoughts:
                t['file'] = json_file.name
                t['key'] = f"{json_file.name}_{t['step']}"
            all_thoughts.extend(thoughts)
        
        print(f"ğŸ“ ì´ {len(all_thoughts)}ê°œì˜ Thought ë°œê²¬")
        
        # Step 2: joblibìœ¼ë¡œ ë³‘ë ¬ LLM ë¶„ì„
        def analyze_thought_wrapper(thought_data: dict) -> tuple[str, str | None]:
            
            if thought_data['thought']:
                result = analyze_single_thought_with_llm(
                    thought_data['thought'],
                    model=llm_model
                )
                return thought_data['key'], result
            return thought_data['key'], None
        
        if verbose:
            print(f"ğŸ”„ LLM ë³‘ë ¬ ë¶„ì„ ì¤‘...")
        
        llm_results_list = Parallel(n_jobs=n_jobs, backend='threading')(
            delayed(analyze_thought_wrapper)(t) 
            for t in tqdm(all_thoughts, desc="LLM ë¶„ì„", disable=not verbose)
        )
        
        llm_results = dict(llm_results_list)
        
        # Step 3: ê²°ê³¼ ì§‘ê³„
        file_results_list = Parallel(n_jobs=n_jobs)(
            delayed(analyze_file_parallel)(str(json_file), llm_results)
            for json_file in tqdm(json_files, desc="ê²°ê³¼ ì§‘ê³„", disable=not verbose)
        )
        
        for filename, file_results in file_results_list:
            all_results['total_files'] += 1
            all_results['total_steps'] += file_results['total_steps']
            all_results['total_matched'] += file_results['matched']
            all_results['total_mismatched'] += file_results['mismatched']
            all_results['total_unknown'] += file_results['unknown']
            all_results['files'][filename] = file_results
            
            for mismatch in file_results['mismatches']:
                mismatch['file'] = filename
                all_results['all_mismatches'].append(mismatch)
    
    else:
        # Rule-based (ê¸°ì¡´ ë¡œì§)
        for idx, json_file in enumerate(json_files):
            if verbose:
                print(f"\rğŸ“„ ë¶„ì„ ì¤‘: {idx + 1}/{len(json_files)} - {json_file.name}", end="")
            
            try:
                file_results = analyze_file(str(json_file), use_llm=False)
                all_results['total_files'] += 1
                all_results['total_steps'] += file_results['total_steps']
                all_results['total_matched'] += file_results['matched']
                all_results['total_mismatched'] += file_results['mismatched']
                all_results['total_unknown'] += file_results['unknown']
                all_results['files'][json_file.name] = file_results
                
                for mismatch in file_results['mismatches']:
                    mismatch['file'] = json_file.name
                    all_results['all_mismatches'].append(mismatch)
                    
            except Exception as e:
                if verbose:
                    print(f"\nError processing {json_file}: {e}")
        
        if verbose:
            print()
    
    return all_results


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Thought-Action ë¶ˆì¼ì¹˜ ë¶„ì„ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # Rule-based ë¶„ì„ (ê¸°ë³¸)
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react
  
  # LLM ê¸°ë°˜ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬)
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --use-llm
  
  # ë³‘ë ¬ ì‘ì—… ìˆ˜ ì§€ì •
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --use-llm --n-jobs 8
  
  # íŠ¹ì • LLM ëª¨ë¸ ì‚¬ìš©
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --use-llm --llm-model gpt-4o
  
  # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --detailed
  
  # ê²°ê³¼ JSONìœ¼ë¡œ ì €ì¥
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --output report.json
  
  # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ statsë§Œ ì¬ê³„ì‚°
  python sampling_error_analysis.py results/sokoban_2/gpt-4.1-mini/react --output report.json --update-only
        """
    )
    parser.add_argument('folder', help='ë¶„ì„í•  í´ë” ê²½ë¡œ')
    parser.add_argument('--use-llm', action='store_true', 
                        help='LLMì„ ì‚¬ìš©í•˜ì—¬ Thought ë¶„ì„ (ê¸°ë³¸: rule-based)')
    parser.add_argument('--llm-model', default='gpt-4.1-mini',
                        help='LLM ë¶„ì„ì— ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: gpt-4.1-mini)')
    parser.add_argument('--n-jobs', type=int, default=-1,
                        help='ë³‘ë ¬ ì‘ì—… ìˆ˜ (-1: ëª¨ë“  CPU ì‚¬ìš©, ê¸°ë³¸: -1)')
    parser.add_argument('--detailed', '-d', action='store_true', 
                        help='íŒŒì¼ë³„ ìƒì„¸ ê²°ê³¼ ì¶œë ¥')
    parser.add_argument('--output', '-o', help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥')
    parser.add_argument('--show-unknown', action='store_true', 
                        help='ì¶”ë¡  ë¶ˆê°€ ì¼€ì´ìŠ¤ë„ ìƒì„¸ ì¶œë ¥')
    parser.add_argument('--update-only', '-u', action='store_true',
                        help='ê¸°ì¡´ ì¶œë ¥ íŒŒì¼ì´ ìˆìœ¼ë©´ statsë§Œ ì¬ê³„ì‚°í•˜ì—¬ ì—…ë°ì´íŠ¸')
    
    args = parser.parse_args()
    
    # --update-only ëª¨ë“œ: ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ statsë§Œ ì¬ê³„ì‚°
    if args.update_only and args.output and os.path.exists(args.output):
        print(f"ğŸ“„ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {args.output}")
        print(f"ğŸ”„ Stats ì¬ê³„ì‚° ì¤‘...")
        
        try:
            updated_data = recalculate_stats_from_file(args.output)
            
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(updated_data, f, indent=2, ensure_ascii=False)
            
            print(f"\nâœ… Stats ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            print(f"   - ì „ì²´ ìŠ¤í…: {updated_data['total_steps']}")
            print(f"   - âœ… ì¼ì¹˜: {updated_data['match_rate_formatted']}")
            print(f"   - âŒ ë¶ˆì¼ì¹˜: {updated_data['mismatch_rate_formatted']}")
            print(f"   - â“ ì¶”ë¡  ë¶ˆê°€: {updated_data['unknown_rate_formatted']}")
            print(f"\nğŸ’¾ ì €ì¥ë¨: {args.output}")
            return
            
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            print(f"ğŸ”„ ì „ì²´ ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    
    method = "LLM" if args.use_llm else "Rule-based"
    print(f"ğŸ” ë¶„ì„ ì‹œì‘: {args.folder}")
    print(f"ğŸ”§ ë¶„ì„ ë°©ë²•: {method}")
    if args.use_llm:
        print(f"âš¡ ë³‘ë ¬ ì‘ì—… ìˆ˜: {args.n_jobs}")
    
    results = analyze_folder(
        args.folder,
        use_llm=args.use_llm,
        llm_model=args.llm_model,
        n_jobs=args.n_jobs
    )
    
    if not results or results['total_files'] == 0:
        print("ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print_summary(results)
    
    if args.detailed:
        print_file_breakdown(results)
    
    if args.show_unknown and results.get('total_unknown', 0) > 0:
        print("\n" + "=" * 60)
        print("â“ ì¶”ë¡  ë¶ˆê°€ ì¼€ì´ìŠ¤ (ìµœëŒ€ 5ê°œ):")
        print("=" * 60)
        count = 0
        for filename, file_results in results['files'].items():
            for case in file_results.get('unknown_cases', []):
                if count >= 5:
                    break
                print(f"\níŒŒì¼: {filename}, Step: {case['step']}")
                print(f"ì‹¤ì œ Action: {case['actual_action']}")
                if case.get('observation'):
                    print(f"Observation: {case['observation'][:200]}...")
                if case.get('steps_remaining') is not None:
                    print(f"Steps Remaining: {case['steps_remaining']}")
                if case.get('thought'):
                    thought_preview = case['thought'][:300].replace('\n', ' ')
                    print(f"Thought: {thought_preview}...")
                count += 1
    
    if args.output:
        total = max(results['total_steps'], 1)
        match_rate = results['total_matched'] / total
        mismatch_rate = results['total_mismatched'] / total
        unknown_rate = results['total_unknown'] / total
        
        # Standard Error ê³„ì‚°
        match_se = math.sqrt(match_rate * (1 - match_rate) / total) if total > 1 else 0.0
        mismatch_se = math.sqrt(mismatch_rate * (1 - mismatch_rate) / total) if total > 1 else 0.0
        unknown_se = math.sqrt(unknown_rate * (1 - unknown_rate) / total) if total > 1 else 0.0
        
        # ëª¨ë“  step_logs ìˆ˜ì§‘
        all_step_logs = []
        for filename, file_results in results['files'].items():
            for log in file_results.get('step_logs', []):
                log['file'] = filename
                all_step_logs.append(log)
        
        save_results = {
            'folder': results['folder'],
            'analysis_method': results['analysis_method'],
            'llm_model': results.get('llm_model'),
            'total_files': results['total_files'],
            'total_steps': results['total_steps'],
            'total_matched': results['total_matched'],
            'total_mismatched': results['total_mismatched'],
            'total_unknown': results['total_unknown'],
            # ë¹„ìœ¨ ë° Standard Error ì¶”ê°€
            'match_rate': match_rate,
            'match_se': match_se,
            'match_rate_formatted': f"{match_rate:.3f} Â± {match_se:.3f}",
            'mismatch_rate': mismatch_rate,
            'mismatch_se': mismatch_se,
            'mismatch_rate_formatted': f"{mismatch_rate:.3f} Â± {mismatch_se:.3f}",
            'unknown_rate': unknown_rate,
            'unknown_se': unknown_se,
            'unknown_rate_formatted': f"{unknown_rate:.3f} Â± {unknown_se:.3f}",
            'files_summary': {
                name: {
                    'total': r['total_steps'],
                    'matched': r['matched'],
                    'mismatched': r['mismatched'],
                    'unknown': r['unknown'],
                    'match_rate': r['matched'] / max(r['total_steps'], 1),
                    'mismatch_rate': r['mismatched'] / max(r['total_steps'], 1),
                }
                for name, r in results['files'].items()
            },
            # ëª¨ë“  stepì˜ ìƒì„¸ ë¡œê·¸ (observation, steps_remaining, inferred, actual í¬í•¨)
            'all_step_logs': all_step_logs,
            'all_mismatches': [
                {
                    'file': m['file'],
                    'step': m['step'],
                    'observation': m.get('observation', '')[:300] if m.get('observation') else None,
                    'steps_remaining': m.get('steps_remaining'),
                    'inferred': m['inferred_action'],
                    'actual': m['actual_action'],
                    'thought': m.get('thought', '')[:300]
                }
                for m in results['all_mismatches']
            ]
        }
        
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(save_results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {args.output}")


if __name__ == '__main__':
    main()
